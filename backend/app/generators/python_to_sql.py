"""
Python-to-SQL Generator
Converts SQLAlchemy models to PostgreSQL DDL

This is the first of DevMaster's three Platform Primitives.
It automates the conversion of Python SQLAlchemy models into
production-ready PostgreSQL CREATE TABLE statements.
"""

from typing import Type, List, Dict, Any, Optional, Set
from sqlalchemy.ext.declarative import DeclarativeMeta
from sqlalchemy import inspect, Column, ForeignKey
from sqlalchemy.sql import sqltypes
from sqlalchemy.dialects import postgresql
import logging

logger = logging.getLogger(__name__)


class PythonToSQLGenerator:
    """Generates PostgreSQL DDL from SQLAlchemy models."""
    
    # Type mapping from SQLAlchemy to PostgreSQL
    TYPE_MAP = {
        sqltypes.String: "VARCHAR",
        sqltypes.Text: "TEXT",
        sqltypes.Integer: "INTEGER",
        sqltypes.BigInteger: "BIGINT",
        sqltypes.SmallInteger: "SMALLINT",
        sqltypes.Boolean: "BOOLEAN",
        sqltypes.DateTime: "TIMESTAMP",
        sqltypes.Date: "DATE",
        sqltypes.Time: "TIME",
        sqltypes.Float: "REAL",
        sqltypes.Numeric: "NUMERIC",
        sqltypes.JSON: "JSON",
        postgresql.UUID: "UUID",
        postgresql.JSONB: "JSONB",
        postgresql.ARRAY: "ARRAY",
        postgresql.INET: "INET",
    }
    
    def __init__(self):
        self.generated_tables: Set[str] = set()
        self.foreign_keys: List[str] = []
        self.indexes: List[str] = []
    
    def generate(self, model: Type[DeclarativeMeta]) -> str:
        """
        Convert a SQLAlchemy model to PostgreSQL CREATE TABLE statement.
        
        Args:
            model: SQLAlchemy model class
            
        Returns:
            PostgreSQL DDL as a string
        """
        try:
            inspector = inspect(model)
            table_name = model.__tablename__
            
            # Reset collections for this generation
            self.foreign_keys = []
            self.indexes = []
            
            # Generate CREATE TABLE statement
            create_table = self._generate_create_table(model, inspector, table_name)
            
            # Generate indexes
            index_statements = self._generate_indexes(model, inspector, table_name)
            
            # Generate foreign key constraints (as separate ALTER TABLE statements)
            fk_statements = self._generate_foreign_keys()
            
            # Combine all statements
            all_statements = [create_table] + index_statements + fk_statements
            
            # Add table to generated set
            self.generated_tables.add(table_name)
            
            return "\n\n".join(all_statements)
            
        except Exception as e:
            logger.error(f"Error generating SQL for model {model.__name__}: {str(e)}")
            raise
    
    def generate_multiple(self, models: List[Type[DeclarativeMeta]]) -> str:
        """
        Generate SQL for multiple models, handling dependencies.
        
        Args:
            models: List of SQLAlchemy model classes
            
        Returns:
            Complete PostgreSQL DDL script
        """
        # Sort models by dependencies
        sorted_models = self._sort_by_dependencies(models)
        
        # Generate SQL for each model
        sql_statements = []
        for model in sorted_models:
            sql = self.generate(model)
            sql_statements.append(sql)
        
        # Add header comment
        header = "-- Generated by DevMaster Python-to-SQL Generator\n-- PostgreSQL DDL Script\n"
        
        return header + "\n\n".join(sql_statements)
    
    def _generate_create_table(self, model: Type[DeclarativeMeta], 
                              inspector: Any, table_name: str) -> str:
        """Generate the CREATE TABLE statement."""
        columns = []
        
        for column in inspector.columns:
            col_def = self._generate_column_definition(column)
            columns.append(col_def)
        
        # Add any table-level constraints
        constraints = self._generate_table_constraints(model, inspector)
        if constraints:
            columns.extend(constraints)
        
        column_definitions = ",\n    ".join(columns)
        
        return f"CREATE TABLE {table_name} (\n    {column_definitions}\n);"
    
    def _generate_column_definition(self, column: Column) -> str:
        """Generate a single column definition."""
        parts = [column.name]
        
        # Get PostgreSQL type
        pg_type = self._get_postgresql_type(column.type)
        parts.append(pg_type)
        
        # Handle primary key
        if column.primary_key:
            parts.append("PRIMARY KEY")
        
        # Handle nullable
        if not column.nullable:
            parts.append("NOT NULL")
        
        # Handle unique
        if column.unique and not column.primary_key:
            parts.append("UNIQUE")
        
        # Handle default values
        if column.default is not None:
            default_val = self._format_default(column.default)
            if default_val:
                parts.append(f"DEFAULT {default_val}")
        elif column.server_default is not None:
            # Handle server defaults like func.now()
            default_val = self._format_server_default(column.server_default)
            if default_val:
                parts.append(f"DEFAULT {default_val}")
        
        # Check if this is a foreign key
        if column.foreign_keys:
            for fk in column.foreign_keys:
                self._register_foreign_key(column.name, fk)
        
        # Check if column should be indexed
        if column.index and not column.primary_key:
            self._register_index(column.table.name, column.name)
        
        return " ".join(parts)
    
    def _get_postgresql_type(self, sqlalchemy_type: sqltypes.TypeEngine) -> str:
        """Convert SQLAlchemy type to PostgreSQL type."""
        # Check for length/precision parameters
        type_str = ""
        
        # Handle Text type explicitly before checking String
        if isinstance(sqlalchemy_type, sqltypes.Text):
            return "TEXT"
        
        # Check for exact type matches first (more specific types)
        # This ensures BigInteger doesn't match as Integer
        type_class = type(sqlalchemy_type)
        
        # Direct type mapping for specific types
        if type_class == sqltypes.BigInteger:
            return "BIGINT"
        elif type_class == sqltypes.SmallInteger:
            return "SMALLINT"
        elif isinstance(sqlalchemy_type, postgresql.JSONB):
            return "JSONB"
        
        # Find the base type class
        for base_type, pg_type in self.TYPE_MAP.items():
            if isinstance(sqlalchemy_type, base_type):
                type_str = pg_type
                break
        
        if not type_str:
            # Default fallback
            type_str = "TEXT"
            logger.warning(f"Unknown type {type(sqlalchemy_type).__name__}, using TEXT")
        
        # Handle parameterized types
        if isinstance(sqlalchemy_type, sqltypes.String) and sqlalchemy_type.length:
            type_str = f"VARCHAR({sqlalchemy_type.length})"
        elif isinstance(sqlalchemy_type, sqltypes.Numeric):
            if sqlalchemy_type.precision is not None:
                if sqlalchemy_type.scale is not None:
                    type_str = f"NUMERIC({sqlalchemy_type.precision}, {sqlalchemy_type.scale})"
                else:
                    type_str = f"NUMERIC({sqlalchemy_type.precision})"
        elif isinstance(sqlalchemy_type, sqltypes.DateTime) and sqlalchemy_type.timezone:
            type_str = "TIMESTAMP WITH TIME ZONE"
        elif isinstance(sqlalchemy_type, postgresql.ARRAY):
            item_type = self._get_postgresql_type(sqlalchemy_type.item_type)
            type_str = f"{item_type}[]"
        
        return type_str
    
    def _format_default(self, default: Any) -> Optional[str]:
        """Format a Python default value for SQL."""
        if hasattr(default, 'arg'):
            # It's a ColumnDefault
            value = default.arg
            if callable(value):
                # Handle callables like uuid.uuid4
                if value.__name__ == 'uuid4':
                    return "gen_random_uuid()"
                elif value == dict:
                    # Handle dict default for JSON columns
                    return "'{}'"
                else:
                    # Can't translate arbitrary Python functions
                    return None
            else:
                return self._format_value(value)
        else:
            return self._format_value(default)
    
    def _format_server_default(self, server_default: Any) -> Optional[str]:
        """Format a server default value."""
        if hasattr(server_default, 'arg'):
            arg = server_default.arg
            if hasattr(arg, 'name'):
                # Handle func.now() and similar
                if arg.name == 'now':
                    return "CURRENT_TIMESTAMP"
            return str(arg)
        return None
    
    def _format_value(self, value: Any) -> str:
        """Format a Python value for SQL."""
        if value is None:
            return "NULL"
        elif isinstance(value, bool):
            return "TRUE" if value else "FALSE"
        elif isinstance(value, str):
            # Escape single quotes
            escaped = value.replace("'", "''")
            return f"'{escaped}'"
        elif isinstance(value, (int, float)):
            return str(value)
        elif isinstance(value, dict):
            # JSON default
            import json
            return f"'{json.dumps(value)}'::json"
        else:
            return f"'{str(value)}'"
    
    def _generate_table_constraints(self, model: Type[DeclarativeMeta], 
                                   inspector: Any) -> List[str]:
        """Generate table-level constraints."""
        constraints = []
        
        # Check for composite primary keys
        pk_cols = [col.name for col in inspector.columns if col.primary_key]
        if len(pk_cols) > 1:
            pk_list = ", ".join(pk_cols)
            constraints.append(f"PRIMARY KEY ({pk_list})")
        
        # Check for unique constraints at table level
        if hasattr(model, '__table_args__'):
            # TODO: Parse __table_args__ for additional constraints
            pass
        
        return constraints
    
    def _register_foreign_key(self, column_name: str, fk: ForeignKey) -> None:
        """Register a foreign key for later generation."""
        target = str(fk.target_fullname)
        target_table, target_column = target.split('.')
        
        # Store FK info for later generation
        self.foreign_keys.append({
            'column': column_name,
            'target_table': target_table,
            'target_column': target_column,
            'fk': fk
        })
    
    def _register_index(self, table_name: str, column_name: str) -> None:
        """Register an index for later generation."""
        index_name = f"ix_{table_name}_{column_name}"
        self.indexes.append({
            'table': table_name,
            'column': column_name,
            'name': index_name
        })
    
    def _generate_foreign_keys(self) -> List[str]:
        """Generate ALTER TABLE statements for foreign keys."""
        fk_statements = []
        
        for fk_info in self.foreign_keys:
            table_name = fk_info['fk'].parent.table.name
            constraint_name = f"fk_{table_name}_{fk_info['column']}_{fk_info['target_table']}"
            
            stmt = (
                f"ALTER TABLE {table_name} ADD CONSTRAINT {constraint_name} "
                f"FOREIGN KEY ({fk_info['column']}) REFERENCES {fk_info['target_table']}({fk_info['target_column']})"
            )
            
            # Add ON DELETE/UPDATE actions if specified
            if fk_info['fk'].ondelete:
                stmt += f" ON DELETE {fk_info['fk'].ondelete}"
            if fk_info['fk'].onupdate:
                stmt += f" ON UPDATE {fk_info['fk'].onupdate}"
            
            stmt += ";"
            fk_statements.append(stmt)
        
        return fk_statements
    
    def _generate_indexes(self, model: Type[DeclarativeMeta], 
                         inspector: Any, table_name: str) -> List[str]:
        """Generate CREATE INDEX statements."""
        index_statements = []
        
        for index_info in self.indexes:
            if index_info['table'] == table_name:
                stmt = f"CREATE INDEX {index_info['name']} ON {index_info['table']} ({index_info['column']});"
                index_statements.append(stmt)
        
        return index_statements
    
    def _sort_by_dependencies(self, models: List[Type[DeclarativeMeta]]) -> List[Type[DeclarativeMeta]]:
        """Sort models by their foreign key dependencies."""
        # Build dependency graph
        dependencies = {}
        model_by_table = {}
        
        for model in models:
            table_name = model.__tablename__
            model_by_table[table_name] = model
            dependencies[table_name] = set()
            
            # Find all foreign key dependencies
            inspector = inspect(model)
            for column in inspector.columns:
                for fk in column.foreign_keys:
                    target_table = fk.target_fullname.split('.')[0]
                    if target_table != table_name:  # Avoid self-references
                        dependencies[table_name].add(target_table)
        
        # Topological sort
        sorted_tables = []
        visited = set()
        
        def visit(table: str):
            if table in visited:
                return
            visited.add(table)
            
            # Visit dependencies first
            for dep in dependencies.get(table, set()):
                if dep in model_by_table:  # Only if we're generating the dependency
                    visit(dep)
            
            sorted_tables.append(table)
        
        # Visit all tables
        for table in dependencies:
            visit(table)
        
        # Convert back to models
        return [model_by_table[table] for table in sorted_tables if table in model_by_table]
