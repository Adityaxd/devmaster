"""
File System Service

Core service for managing project file structures and operations.
Provides atomic file operations and virtual file system capabilities.
"""

import os
import json
import asyncio
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
from datetime import datetime, timezone
import aiofiles
import aiofiles.os
from pydantic import BaseModel, Field
import logging

from app.config import settings
from app.core.events import EventBus, EventType

logger = logging.getLogger(__name__)


class FileNode(BaseModel):
    """Represents a file or directory in the virtual file system."""
    
    name: str
    path: str
    type: str = Field(description="file or directory")
    content: Optional[str] = Field(default=None, description="File content for files")
    children: Optional[Dict[str, 'FileNode']] = Field(default=None, description="Child nodes for directories")
    size: int = Field(default=0, description="File size in bytes")
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    modified_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    permissions: str = Field(default="rw-r--r--")
    
    class Config:
        arbitrary_types_allowed = True


class FileOperation(BaseModel):
    """Represents a file system operation for atomic execution."""
    
    operation: str = Field(description="Operation type: create, update, delete, move")
    path: str = Field(description="Target file/directory path")
    content: Optional[str] = Field(default=None, description="Content for create/update operations")
    destination: Optional[str] = Field(default=None, description="Destination path for move operations")
    metadata: Dict[str, Any] = Field(default_factory=dict)


class FileSystemService:
    """
    Service for managing project file systems.
    
    Provides:
    - Virtual file system representation
    - Atomic file operations
    - File system snapshots
    - Rollback capabilities
    """
    
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self.base_path = Path(settings.projects_base_path)
        self._ensure_base_directory()
    
    def _ensure_base_directory(self):
        """Ensure the base projects directory exists."""
        self.base_path.mkdir(parents=True, exist_ok=True)
    
    def _get_project_path(self, project_id: str) -> Path:
        """Get the filesystem path for a project."""
        return self.base_path / project_id
    
    async def initialize_project_structure(self, project_id: str) -> Dict[str, Any]:
        """
        Initialize a new project's file structure.
        
        Creates the base directory structure for a project.
        """
        try:
            project_path = self._get_project_path(project_id)
            
            # Create base directories
            directories = [
                "src",
                "src/backend",
                "src/backend/app",
                "src/backend/app/models",
                "src/backend/app/services",
                "src/backend/app/routers",
                "src/backend/tests",
                "src/frontend",
                "src/frontend/src",
                "src/frontend/src/components",
                "src/frontend/src/pages",
                "src/frontend/src/services",
                "src/frontend/public",
                "docs",
                "scripts",
                ".devmaster"
            ]
            
            for dir_path in directories:
                full_path = project_path / dir_path
                await aiofiles.os.makedirs(str(full_path), exist_ok=True)
            
            # Create initial files
            initial_files = {
                "README.md": f"# Project {project_id}\n\nGenerated by DevMaster",
                ".gitignore": self._generate_gitignore(),
                "src/backend/requirements.txt": "fastapi>=0.104.0\nsqlalchemy>=2.0.0\npsycopg2-binary>=2.9.0\n",
                "src/frontend/package.json": self._generate_package_json(project_id),
                ".devmaster/metadata.json": json.dumps({
                    "project_id": project_id,
                    "created_at": datetime.now(timezone.utc).isoformat(),
                    "version": "0.1.0",
                    "status": "initialized"
                }, indent=2)
            }
            
            for file_path, content in initial_files.items():
                full_path = project_path / file_path
                async with aiofiles.open(str(full_path), 'w') as f:
                    await f.write(content)
            
            # Create virtual file system representation
            vfs = await self._build_virtual_fs(project_path)
            
            # Emit event
            await self.event_bus.emit(
                EventType.PROJECT_FILE_SYSTEM_INITIALIZED,
                {
                    "project_id": project_id,
                    "path": str(project_path),
                    "structure": vfs
                }
            )
            
            return {
                "success": True,
                "project_path": str(project_path),
                "virtual_fs": vfs
            }
            
        except Exception as e:
            logger.error(f"Error initializing project structure: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def read_file(self, project_id: str, file_path: str) -> Dict[str, Any]:
        """Read a file from the project."""
        try:
            project_path = self._get_project_path(project_id)
            full_path = project_path / file_path
            
            if not full_path.exists():
                return {
                    "success": False,
                    "error": f"File not found: {file_path}"
                }
            
            if not full_path.is_file():
                return {
                    "success": False,
                    "error": f"Path is not a file: {file_path}"
                }
            
            async with aiofiles.open(str(full_path), 'r') as f:
                content = await f.read()
            
            return {
                "success": True,
                "content": content,
                "path": file_path,
                "size": full_path.stat().st_size
            }
            
        except Exception as e:
            logger.error(f"Error reading file: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def write_file(
        self, 
        project_id: str, 
        file_path: str, 
        content: str,
        create_dirs: bool = True
    ) -> Dict[str, Any]:
        """Write content to a file in the project."""
        try:
            project_path = self._get_project_path(project_id)
            full_path = project_path / file_path
            
            # Create parent directories if needed
            if create_dirs:
                await aiofiles.os.makedirs(str(full_path.parent), exist_ok=True)
            
            # Write file
            async with aiofiles.open(str(full_path), 'w') as f:
                await f.write(content)
            
            # Emit event
            await self.event_bus.emit(
                EventType.PROJECT_FILE_CREATED,
                {
                    "project_id": project_id,
                    "file_path": file_path,
                    "size": len(content)
                }
            )
            
            return {
                "success": True,
                "path": file_path,
                "size": len(content)
            }
            
        except Exception as e:
            logger.error(f"Error writing file: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def delete_file(self, project_id: str, file_path: str) -> Dict[str, Any]:
        """Delete a file from the project."""
        try:
            project_path = self._get_project_path(project_id)
            full_path = project_path / file_path
            
            if not full_path.exists():
                return {
                    "success": False,
                    "error": f"File not found: {file_path}"
                }
            
            if full_path.is_file():
                await aiofiles.os.remove(str(full_path))
            else:
                # Use shutil for directory removal
                import shutil
                await asyncio.to_thread(shutil.rmtree, str(full_path))
            
            # Emit event
            await self.event_bus.emit(
                EventType.PROJECT_FILE_DELETED,
                {
                    "project_id": project_id,
                    "file_path": file_path
                }
            )
            
            return {
                "success": True,
                "path": file_path
            }
            
        except Exception as e:
            logger.error(f"Error deleting file: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def execute_atomic_operations(
        self, 
        project_id: str, 
        operations: List[FileOperation]
    ) -> Dict[str, Any]:
        """
        Execute multiple file operations atomically.
        
        All operations succeed or all fail.
        """
        executed = []
        
        try:
            for op in operations:
                if op.operation == "create":
                    result = await self.write_file(
                        project_id, 
                        op.path, 
                        op.content or ""
                    )
                elif op.operation == "update":
                    result = await self.write_file(
                        project_id, 
                        op.path, 
                        op.content or ""
                    )
                elif op.operation == "delete":
                    result = await self.delete_file(project_id, op.path)
                elif op.operation == "move":
                    # Implement move as copy + delete
                    read_result = await self.read_file(project_id, op.path)
                    if read_result["success"]:
                        write_result = await self.write_file(
                            project_id, 
                            op.destination, 
                            read_result["content"]
                        )
                        if write_result["success"]:
                            result = await self.delete_file(project_id, op.path)
                        else:
                            result = write_result
                    else:
                        result = read_result
                else:
                    result = {
                        "success": False,
                        "error": f"Unknown operation: {op.operation}"
                    }
                
                if not result["success"]:
                    # Rollback on failure
                    await self._rollback_operations(project_id, executed)
                    return {
                        "success": False,
                        "error": f"Operation failed: {result['error']}",
                        "failed_operation": op.model_dump()
                    }
                
                executed.append(op)
            
            return {
                "success": True,
                "operations_count": len(operations),
                "executed": [op.model_dump() for op in executed]
            }
            
        except Exception as e:
            logger.error(f"Error in atomic operations: {str(e)}")
            await self._rollback_operations(project_id, executed)
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _rollback_operations(
        self, 
        project_id: str, 
        operations: List[FileOperation]
    ):
        """Rollback executed operations."""
        # TODO: Implement proper rollback with snapshots
        logger.warning(f"Rollback requested for {len(operations)} operations")
    
    async def get_virtual_file_system(self, project_id: str) -> Dict[str, Any]:
        """Get the virtual file system representation of a project."""
        try:
            project_path = self._get_project_path(project_id)
            
            if not project_path.exists():
                return {
                    "success": False,
                    "error": f"Project not found: {project_id}"
                }
            
            vfs = await self._build_virtual_fs(project_path)
            
            return {
                "success": True,
                "virtual_fs": vfs,
                "project_id": project_id
            }
            
        except Exception as e:
            logger.error(f"Error building virtual file system: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _build_virtual_fs(self, path: Path, base_path: Optional[Path] = None) -> Dict[str, Any]:
        """Recursively build virtual file system representation."""
        if base_path is None:
            base_path = path
        
        node = {
            "name": path.name,
            "path": str(path.relative_to(base_path)),
            "type": "directory" if path.is_dir() else "file",
            "size": 0,
            "modified_at": datetime.fromtimestamp(path.stat().st_mtime).isoformat()
        }
        
        if path.is_file():
            node["size"] = path.stat().st_size
        else:
            node["children"] = {}
            for item in path.iterdir():
                # Skip hidden files and __pycache__
                if item.name.startswith('.') and item.name != '.devmaster':
                    continue
                if item.name == '__pycache__':
                    continue
                
                child_node = await self._build_virtual_fs(item, base_path)
                node["children"][item.name] = child_node
        
        return node
    
    def _generate_gitignore(self) -> str:
        """Generate a standard .gitignore file."""
        return """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
.env
.venv

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Project
.devmaster/snapshots/
.devmaster/temp/
*.log
"""
    
    def _generate_package_json(self, project_name: str) -> str:
        """Generate a basic package.json file."""
        return json.dumps({
            "name": project_name.lower().replace(" ", "-"),
            "version": "0.1.0",
            "private": True,
            "scripts": {
                "dev": "vite",
                "build": "tsc && vite build",
                "preview": "vite preview"
            },
            "dependencies": {
                "react": "^18.2.0",
                "react-dom": "^18.2.0"
            },
            "devDependencies": {
                "@types/react": "^18.2.0",
                "@types/react-dom": "^18.2.0",
                "@vitejs/plugin-react": "^4.0.0",
                "typescript": "^5.0.0",
                "vite": "^5.0.0"
            }
        }, indent=2)


# Model update for better integration
FileNode.model_rebuild()  # Rebuild model to handle forward references
